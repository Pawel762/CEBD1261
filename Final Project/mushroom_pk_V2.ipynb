{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CEBD 1261 Winter 2020\n",
    "## Final Project: Mushroom classification (Poisonous (p) vs. Edible (e))\n",
    "### Data source: https://www.kaggle.com/uciml/mushroom-classification \n",
    "### By: Pawel Kaluski\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching for data to use for my project I found this one. It is a classification problem. \n",
    "The challenge with this dataset was that it only has characters and no numbers. It required a lot of encoding. The second issue was to make the model fit with the pipeline. \n",
    "\n",
    "I ended adapting the code posted on DataBriks site:\n",
    "\n",
    "https://docs.databricks.com/applications/machine-learning/mllib/binary-classification-mllib-pipelines.html\n",
    "\n",
    "Doing this project, I learned how to apply machine learning using spark.\n",
    "\n",
    "To further improve accuracy, we could consider predicting the missing values from \"Stalk-Root\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "import pyspark.sql as sparksql\n",
    "spark = SparkSession.builder.appName('mushrooms').getOrCreate()\n",
    "train = spark.read.csv('mushrooms.csv', inferSchema=True,header=True)\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Used Python to make sure there were no nan in any columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing data for nan\n",
    "df = pd.read_csv('mushrooms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get info of missing data for each col by creading data frame that contains col's name and its NaN value counts\n",
    "nan_info = pd.DataFrame(df.isnull().sum()).reset_index()\n",
    "nan_info.columns = ['col','nan_cnt']\n",
    "nan_info.sort_values(by = 'nan_cnt',ascending=False,inplace=True)\n",
    "nan_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We see there are no nan values in any columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- class: string (nullable = true)\n",
      " |-- cap-shape: string (nullable = true)\n",
      " |-- cap-surface: string (nullable = true)\n",
      " |-- cap-color: string (nullable = true)\n",
      " |-- bruises: string (nullable = true)\n",
      " |-- odor: string (nullable = true)\n",
      " |-- gill-attachment: string (nullable = true)\n",
      " |-- gill-spacing: string (nullable = true)\n",
      " |-- gill-size: string (nullable = true)\n",
      " |-- gill-color: string (nullable = true)\n",
      " |-- stalk-shape: string (nullable = true)\n",
      " |-- stalk-root: string (nullable = true)\n",
      " |-- stalk-surface-above-ring: string (nullable = true)\n",
      " |-- stalk-surface-below-ring: string (nullable = true)\n",
      " |-- stalk-color-above-ring: string (nullable = true)\n",
      " |-- stalk-color-below-ring: string (nullable = true)\n",
      " |-- veil-type: string (nullable = true)\n",
      " |-- veil-color: string (nullable = true)\n",
      " |-- ring-number: string (nullable = true)\n",
      " |-- ring-type: string (nullable = true)\n",
      " |-- spore-print-color: string (nullable = true)\n",
      " |-- population: string (nullable = true)\n",
      " |-- habitat: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next we will look at te different features to determine what's in them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our Target\n",
    "train.groupBy('class').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupBy('cap-shape').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupBy('cap-surface').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupBy('cap-color').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupBy('bruises').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupBy('odor').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupBy('gill-attachment').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupBy('gill-spacing').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupBy('gill-size').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupBy('gill-color').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupBy('stalk-shape').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupBy('stalk-root').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see we have 2480 missing values we can exclude this column in the MVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupBy('stalk-surface-above-ring').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupBy('stalk-surface-below-ring').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupBy('stalk-color-above-ring').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupBy('stalk-color-below-ring').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupBy('veil-color').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupBy('veil-type').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since this feature adds no value it will not be used in our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupBy('ring-number').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupBy('ring-type').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupBy('spore-print-color').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupBy('population').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupBy('habitat').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will remove 'veil-type' and 'stalk-root'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- class: string (nullable = true)\n",
      " |-- cap-shape: string (nullable = true)\n",
      " |-- cap-surface: string (nullable = true)\n",
      " |-- cap-color: string (nullable = true)\n",
      " |-- bruises: string (nullable = true)\n",
      " |-- odor: string (nullable = true)\n",
      " |-- gill-attachment: string (nullable = true)\n",
      " |-- gill-spacing: string (nullable = true)\n",
      " |-- gill-size: string (nullable = true)\n",
      " |-- gill-color: string (nullable = true)\n",
      " |-- stalk-shape: string (nullable = true)\n",
      " |-- stalk-surface-above-ring: string (nullable = true)\n",
      " |-- stalk-surface-below-ring: string (nullable = true)\n",
      " |-- stalk-color-above-ring: string (nullable = true)\n",
      " |-- stalk-color-below-ring: string (nullable = true)\n",
      " |-- veil-color: string (nullable = true)\n",
      " |-- ring-number: string (nullable = true)\n",
      " |-- ring-type: string (nullable = true)\n",
      " |-- spore-print-color: string (nullable = true)\n",
      " |-- population: string (nullable = true)\n",
      " |-- habitat: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = train.select('class', 'cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor', 'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color', 'stalk-shape', 'stalk-surface-above-ring', 'stalk-surface-below-ring', 'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-color', 'ring-number', 'ring-type', 'spore-print-color', 'population', 'habitat')\n",
    "cols = train.columns\n",
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will look at the first 5 rows to see if data is still ok and confirm the columns were removed\n",
    "import pandas as pd\n",
    "pd.DataFrame(train.take(5), columns=train.columns).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This part is where the encoding takes place. (Converting labels to numbers) DataBriks example was used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataBrick example\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\n",
    "categoricalColumns = [\"cap-shape\", \"cap-surface\", \"cap-color\", \"bruises\", \"odor\", \"gill-attachment\", \"gill-spacing\", \n",
    "                      \"gill-size\", \"gill-color\", \"stalk-shape\", \"stalk-surface-above-ring\", \"stalk-surface-below-ring\", \n",
    "                      \"stalk-color-above-ring\", \"stalk-color-below-ring\", \"veil-color\", \"ring-number\", \"ring-type\", \n",
    "                      \"spore-print-color\", \"population\", \"habitat\"]\n",
    "\n",
    "stages = [] # stages in our Pipeline\n",
    "for categoricalCol in categoricalColumns:\n",
    "    # Category Indexing with StringIndexer\n",
    "    stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol + \"Index\")\n",
    "    # Use OneHotEncoder to convert categorical variables into binary SparseVectors\n",
    "    # encoder = OneHotEncoderEstimator(inputCol=categoricalCol + \"Index\", outputCol=categoricalCol + \"classVec\")\n",
    "    encoder = OneHotEncoderEstimator(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
    "    # Add stages.  These are not run here, but will run all at once later on.\n",
    "    stages += [stringIndexer, encoder]\n",
    "    \n",
    "    # Convert label into label indices using the StringIndexer\n",
    "label_stringIdx = StringIndexer(inputCol=\"class\", outputCol=\"label\")\n",
    "stages += [label_stringIdx]\n",
    "\n",
    "assemblerInputs = [c + \"classVec\" for c in categoricalColumns]\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "  \n",
    "partialPipeline = Pipeline().setStages(stages)\n",
    "pipelineModel = partialPipeline.fit(train)\n",
    "preppedDataDF = pipelineModel.transform(train)\n",
    "\n",
    "# Fit model to prepped data\n",
    "lrModel = LogisticRegression().fit(preppedDataDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- class: string (nullable = true)\n",
      " |-- cap-shape: string (nullable = true)\n",
      " |-- cap-surface: string (nullable = true)\n",
      " |-- cap-color: string (nullable = true)\n",
      " |-- bruises: string (nullable = true)\n",
      " |-- odor: string (nullable = true)\n",
      " |-- gill-attachment: string (nullable = true)\n",
      " |-- gill-spacing: string (nullable = true)\n",
      " |-- gill-size: string (nullable = true)\n",
      " |-- gill-color: string (nullable = true)\n",
      " |-- stalk-shape: string (nullable = true)\n",
      " |-- stalk-surface-above-ring: string (nullable = true)\n",
      " |-- stalk-surface-below-ring: string (nullable = true)\n",
      " |-- stalk-color-above-ring: string (nullable = true)\n",
      " |-- stalk-color-below-ring: string (nullable = true)\n",
      " |-- veil-color: string (nullable = true)\n",
      " |-- ring-number: string (nullable = true)\n",
      " |-- ring-type: string (nullable = true)\n",
      " |-- spore-print-color: string (nullable = true)\n",
      " |-- population: string (nullable = true)\n",
      " |-- habitat: string (nullable = true)\n",
      " |-- cap-shapeIndex: double (nullable = false)\n",
      " |-- cap-shapeclassVec: vector (nullable = true)\n",
      " |-- cap-surfaceIndex: double (nullable = false)\n",
      " |-- cap-surfaceclassVec: vector (nullable = true)\n",
      " |-- cap-colorIndex: double (nullable = false)\n",
      " |-- cap-colorclassVec: vector (nullable = true)\n",
      " |-- bruisesIndex: double (nullable = false)\n",
      " |-- bruisesclassVec: vector (nullable = true)\n",
      " |-- odorIndex: double (nullable = false)\n",
      " |-- odorclassVec: vector (nullable = true)\n",
      " |-- gill-attachmentIndex: double (nullable = false)\n",
      " |-- gill-attachmentclassVec: vector (nullable = true)\n",
      " |-- gill-spacingIndex: double (nullable = false)\n",
      " |-- gill-spacingclassVec: vector (nullable = true)\n",
      " |-- gill-sizeIndex: double (nullable = false)\n",
      " |-- gill-sizeclassVec: vector (nullable = true)\n",
      " |-- gill-colorIndex: double (nullable = false)\n",
      " |-- gill-colorclassVec: vector (nullable = true)\n",
      " |-- stalk-shapeIndex: double (nullable = false)\n",
      " |-- stalk-shapeclassVec: vector (nullable = true)\n",
      " |-- stalk-surface-above-ringIndex: double (nullable = false)\n",
      " |-- stalk-surface-above-ringclassVec: vector (nullable = true)\n",
      " |-- stalk-surface-below-ringIndex: double (nullable = false)\n",
      " |-- stalk-surface-below-ringclassVec: vector (nullable = true)\n",
      " |-- stalk-color-above-ringIndex: double (nullable = false)\n",
      " |-- stalk-color-above-ringclassVec: vector (nullable = true)\n",
      " |-- stalk-color-below-ringIndex: double (nullable = false)\n",
      " |-- stalk-color-below-ringclassVec: vector (nullable = true)\n",
      " |-- veil-colorIndex: double (nullable = false)\n",
      " |-- veil-colorclassVec: vector (nullable = true)\n",
      " |-- ring-numberIndex: double (nullable = false)\n",
      " |-- ring-numberclassVec: vector (nullable = true)\n",
      " |-- ring-typeIndex: double (nullable = false)\n",
      " |-- ring-typeclassVec: vector (nullable = true)\n",
      " |-- spore-print-colorIndex: double (nullable = false)\n",
      " |-- spore-print-colorclassVec: vector (nullable = true)\n",
      " |-- populationIndex: double (nullable = false)\n",
      " |-- populationclassVec: vector (nullable = true)\n",
      " |-- habitatIndex: double (nullable = false)\n",
      " |-- habitatclassVec: vector (nullable = true)\n",
      " |-- label: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preppedDataDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, features: vector]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "selectedcols = [\"label\", \"features\"]\n",
    "dataset = preppedDataDF.select(selectedcols)\n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0| 4208|\n",
      "|  1.0| 3916|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|count|\n",
      "+--------------------+-----+\n",
      "|(91,[3,5,12,23,26...|    1|\n",
      "|(91,[0,6,11,23,26...|    1|\n",
      "|(91,[0,5,12,23,26...|    1|\n",
      "|(91,[1,6,11,22,26...|    1|\n",
      "|(91,[1,5,12,24,26...|    1|\n",
      "|(91,[0,7,9,18,26,...|    1|\n",
      "|(91,[1,7,9,17,18,...|    1|\n",
      "|(91,[1,7,8,18,26,...|    1|\n",
      "|(91,[0,7,9,17,19,...|    1|\n",
      "|(91,[0,7,9,18,26,...|    1|\n",
      "|(91,[1,5,9,18,26,...|    1|\n",
      "|(91,[1,7,10,18,26...|    1|\n",
      "|(91,[1,7,9,17,19,...|    1|\n",
      "|(91,[1,7,9,17,19,...|    1|\n",
      "|(91,[1,7,11,17,19...|    1|\n",
      "|(91,[1,7,9,18,26,...|    1|\n",
      "|(91,[1,5,11,17,19...|    1|\n",
      "|(91,[0,7,11,17,19...|    1|\n",
      "|(91,[0,5,12,17,18...|    1|\n",
      "|(91,[12,18,26,31,...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.groupBy('features').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6096\n",
      "2028\n"
     ]
    }
   ],
   "source": [
    "### Randomly split data into training and test sets. set seed for reproducibility\n",
    "(trainingData, testData) = dataset.randomSplit([0.75, 0.25], seed=100)\n",
    "print(trainingData.count())\n",
    "print(testData.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=10)\n",
    "lrModel = lr.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data using the transform() method.\n",
    "# LogisticRegression.transform() will only use the 'features' column.\n",
    "predictions = lrModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, prediction: double]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "selected = predictions.select(\"label\", \"prediction\")\n",
    "display(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, label: string, prediction: string]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Logistic Regression algorithm had an accuracy of: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Evaluating model with the BianaryClassificationEvaluator\n",
    "# Default metric for the BinaryClassificationEvaluator is areaUnderROC\n",
    "\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Evaluate model\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)\n",
    "\n",
    "lr_acc = evaluator.evaluate(predictions)\n",
    "print('A Logistic Regression algorithm had an accuracy of: {0:2.2f}%'.format(lr_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "# Create initial Decision Tree Model\n",
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", maxDepth=3)\n",
    "\n",
    "# Train model with Training Data\n",
    "dtModel = dt.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numNodes =  11\n",
      "depth =  3\n"
     ]
    }
   ],
   "source": [
    "# to list the number of nodes and the tree depth of the model \n",
    "\n",
    "print(\"numNodes = \", dtModel.numNodes)\n",
    "print(\"depth = \", dtModel.depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_d3285945c0ba) of depth 3 with 11 nodes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This can also be done with the following\n",
    "display(dtModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data using the Transformer.transform() method.\n",
    "dtpredictions = dtModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtpredictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Decision Tree algorithm had an accuracy of: 98.02%\n"
     ]
    }
   ],
   "source": [
    "# Evaluating model with the BianaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "# Evaluate model\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "evaluator.evaluate(dtpredictions)\n",
    "dt_acc = evaluator.evaluate(dtpredictions)\n",
    "print('A Decision Tree algorithm had an accuracy of: {0:2.2f}%'.format(dt_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(labelCol='label',featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with Training Data\n",
    "dtcModel = dtc.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcpredictions = dtcModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Decision Tree algorithm had an accuracy of: 99.80%\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "# Select (prediction, true label) and compute test error\n",
    "acc_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "dtc_acc = acc_evaluator.evaluate(dtcpredictions)\n",
    "print('A Decision Tree algorithm had an accuracy of: {0:2.2f}%'.format(dtc_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The last algorithm \" Decision Tree Classifier\" had the best accuracy.\n",
    "#### Despite changing the train/test ratio, it maintained an accuracy of over 99.8%.\n",
    "#### The leaner regression always show 100%. this is not a good sign. Could be over-fitting\n",
    "#### The runner up algorithm, is the Decision Tree. It maintained it's accuracy over 98%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
